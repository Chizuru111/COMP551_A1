{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jxw1CYU2YKmI"
      },
      "source": [
        "# Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "9lPMwC3UWjQD"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "\n",
        "# Set the random seed\n",
        "np.random.seed(1234)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MtYYpBKsYtGU"
      },
      "source": [
        "# Set the device into GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oKt93gSuYzGo",
        "outputId": "b7d28d76-1d69-4d06-ce2f-6d11b827a922"
      },
      "outputs": [],
      "source": [
        "# if torch.cuda.is_available():\n",
        "#   device = torch.device(\"cuda\")\n",
        "# print(f\"Device using: {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "alNW9B1zdjzC"
      },
      "source": [
        "# Install the ucimlrepo package"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "55SqN6DKdsSv"
      },
      "outputs": [],
      "source": [
        "# pip install ucimlrepo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P3XtaLDLZdJd"
      },
      "source": [
        "# Load the dataframe 1 (df1)\n",
        "\n",
        "*   Shape of X: (2278, 10)\n",
        "*   Shape of y: (2278, 1)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "caxbc0cnaZsu"
      },
      "outputs": [],
      "source": [
        "# Dataset 1: NHANES age prediction.csv\n",
        "#(National Health and Nutrition Health Sur- vey 2013-2014 (NHANES) Age Prediction Subset)\n",
        "df1 = pd.read_csv('./dataset/NHANES_age_prediction.csv') # Change it to wherever you store your dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AQ4O7ME3e7bJ"
      },
      "source": [
        "# Load and preprocess the dataset 2 (df2)\n",
        "\n",
        "*   Shape of X: (499, 9)\n",
        "*   Shape of y: (449, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "DyJUoy82e91Y"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "instances (N) \t 449 \n",
            " features (D) \t 9 \n",
            " classes (C) \t [False  True]\n"
          ]
        }
      ],
      "source": [
        "from ucimlrepo import fetch_ucirepo\n",
        "\n",
        "dataset2 = fetch_ucirepo(id=15)\n",
        "X2 = dataset2.data.features\n",
        "y2 = dataset2.data.targets\n",
        "df2 = pd.concat([X2,y2], axis = 1)\n",
        "df2 = df2.drop_duplicates()\n",
        "df2 = df2.dropna()\n",
        "\n",
        "\n",
        "X = df2.iloc[:, :-1].values\n",
        "y = pd.get_dummies(df2.iloc[:, -1]).values\n",
        "\n",
        "# .values: Change the panda dataframe to numpy array\n",
        "\n",
        "# Print the feature shape and classes of dataset\n",
        "(N,D), C = X.shape, np.unique(y)\n",
        "print(f'instances (N) \\t {N} \\n features (D) \\t {D} \\n classes (C) \\t {C}')\n",
        "\n",
        "\n",
        "#generates an indices array from 0 to N-1 and permutes it\n",
        "inds = np.random.permutation(N)\n",
        "\n",
        "train_split, validate_split, test_split = 0.33, 0.33, 0.33\n",
        "\n",
        "# Calculate the indices for each split\n",
        "train_end = int(len(X) * train_split)\n",
        "validate_end = int(len(X) * (train_split + validate_split))\n",
        "\n",
        "# Split the data\n",
        "x_train, y_train = X[inds[:train_end]], y[inds[:train_end]]\n",
        "x_validate, y_validate = X[inds[train_end:validate_end]], y[inds[train_end:validate_end]]\n",
        "x_test, y_test = X[inds[validate_end:]], y[inds[validate_end:]]\n",
        "\n",
        "# Calculate the mean and standard deviation of each feature in the training set\n",
        "mean = np.mean(x_train, axis=0)\n",
        "std = np.std(x_train, axis=0)\n",
        "\n",
        "# Standardize the training data\n",
        "x_train = (x_train - mean) / std\n",
        "\n",
        "# Standardize the validation and test data using the same mean and std\n",
        "x_validate = (x_validate - mean) / std\n",
        "x_test = (x_test - mean) / std"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ulpJIECVhI2S"
      },
      "source": [
        "# Preprocess the dataset 1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gGJBiK7nejSu",
        "outputId": "de526cf0-691f-4064-aed2-65b14dd906f7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2278 entries, 0 to 2277\n",
            "Data columns (total 10 columns):\n",
            " #   Column     Non-Null Count  Dtype  \n",
            "---  ------     --------------  -----  \n",
            " 0   SEQN       2278 non-null   float64\n",
            " 1   age_group  2278 non-null   object \n",
            " 2   RIDAGEYR   2278 non-null   float64\n",
            " 3   RIAGENDR   2278 non-null   float64\n",
            " 4   PAQ605     2278 non-null   float64\n",
            " 5   BMXBMI     2278 non-null   float64\n",
            " 6   LBXGLU     2278 non-null   float64\n",
            " 7   DIQ010     2278 non-null   float64\n",
            " 8   LBXGLT     2278 non-null   float64\n",
            " 9   LBXIN      2278 non-null   float64\n",
            "dtypes: float64(9), object(1)\n",
            "memory usage: 178.1+ KB\n",
            "Note: There is no missing value.\n",
            "\n",
            "instances (N) \t 2278 \n",
            " features (D) \t 7 \n",
            " classes (C) \t [False  True]\n"
          ]
        }
      ],
      "source": [
        "# Basic information of df1\n",
        "df1.info()\n",
        "\n",
        "# Clean the dataset\n",
        "df1.isnull().sum()\n",
        "print(\"Note: There is no missing value.\\n\")\n",
        "\n",
        "# Drop duliplicate\n",
        "df1.drop_duplicates(inplace=True)\n",
        "\n",
        "# As this task is for classification the input feature and the Target variable will be as follows:\n",
        "# Input Feature : ['RIAGENDR', 'PAQ605', 'BMXBMI', 'LBXGLU', 'DIQ010', 'LBXGLT', 'LBXIN']\n",
        "# Target : ['age_group']\n",
        "X = df1[['RIAGENDR', 'PAQ605', 'BMXBMI', 'LBXGLU', 'DIQ010', 'LBXGLT', 'LBXIN']].values\n",
        "y = pd.get_dummies(df1['age_group']).values # One-hot encoding (Change the categorial y into integer array)\n",
        "\n",
        "# .values: Change the panda dataframe to numpy array\n",
        "\n",
        "# Print the feature shape and classes of dataset\n",
        "(N,D), C = X.shape, np.unique(y)\n",
        "print(f'instances (N) \\t {N} \\n features (D) \\t {D} \\n classes (C) \\t {C}')\n",
        "\n",
        "\n",
        "#generates an indices array from 0 to N-1 and permutes it\n",
        "inds = np.random.permutation(N)\n",
        "\n",
        "train_split, validate_split, test_split = 0.33, 0.33, 0.33\n",
        "\n",
        "# Calculate the indices for each split\n",
        "train_end = int(len(X) * train_split)\n",
        "validate_end = int(len(X) * (train_split + validate_split))\n",
        "\n",
        "# Split the data\n",
        "x_train, y_train = X[inds[:train_end]], y[inds[:train_end]]\n",
        "x_validate, y_validate = X[inds[train_end:validate_end]], y[inds[train_end:validate_end]]\n",
        "x_test, y_test = X[inds[validate_end:]], y[inds[validate_end:]]\n",
        "\n",
        "# Calculate the mean and standard deviation of each feature in the training set\n",
        "mean = np.mean(x_train, axis=0)\n",
        "std = np.std(x_train, axis=0)\n",
        "\n",
        "# Standardize the training data\n",
        "x_train = (x_train - mean) / std\n",
        "\n",
        "# Standardize the validation and test data using the same mean and std\n",
        "x_validate = (x_validate - mean) / std\n",
        "x_test = (x_test - mean) / std"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TiMogxf97b84"
      },
      "source": [
        "# KNN model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "ADLslihw7d_I"
      },
      "outputs": [],
      "source": [
        "class KNN:\n",
        "    def __init__(self, K, distance_fn):\n",
        "        self.K = K\n",
        "        self.distance_fn = distance_fn\n",
        "        return\n",
        "\n",
        "    def fit(self, x, y):\n",
        "        self.x = x\n",
        "        self.y = y\n",
        "\n",
        "        # Number of labels\n",
        "        self.C = len(np.unique(y))\n",
        "        return self\n",
        "\n",
        "    def predict(self, x_test):\n",
        "        # Calculate distances using the distance function\n",
        "        distances = self.distance_fn(self.x[None,:,:], x_test[:,None,:])\n",
        "\n",
        "        num_test = len(x_test)\n",
        "        # Stores the indices of k closest training samples to each test sample\n",
        "        knns = np.zeros((num_test, self.K), dtype=int)\n",
        "        # Stores the probability distribution over C classes\n",
        "        y_prob = np.zeros((num_test, self.C))\n",
        "\n",
        "        for i in range(num_test):\n",
        "            knn_indices = np.argsort(distances[i])[:self.K]\n",
        "            for k in knn_indices:\n",
        "                neighbor_label_vector = self.y[k]\n",
        "                weight = 1 / (distances[i][k] + 1e-5)  # inverse distance as weight\n",
        "                y_prob[i] += weight * neighbor_label_vector\n",
        "\n",
        "        y_pred = np.argmax(y_prob, axis=1)\n",
        "        return y_pred\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jCBuoFLRA5bN"
      },
      "source": [
        "# Choose the best hyperparameter K"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1IC1KBkwA44E",
        "outputId": "8a6b9a1a-389d-4457-dee7-b94a1d5c2404"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "K = 1, Validation Accuracy = 93.24%\n",
            "K = 2, Validation Accuracy = 93.24%\n",
            "K = 3, Validation Accuracy = 95.27%\n",
            "K = 4, Validation Accuracy = 95.27%\n",
            "K = 5, Validation Accuracy = 95.95%\n",
            "K = 6, Validation Accuracy = 95.95%\n",
            "K = 7, Validation Accuracy = 95.95%\n",
            "K = 8, Validation Accuracy = 96.62%\n",
            "K = 9, Validation Accuracy = 95.95%\n",
            "K = 10, Validation Accuracy = 96.62%\n",
            "K = 11, Validation Accuracy = 95.27%\n",
            "K = 12, Validation Accuracy = 95.95%\n",
            "K = 13, Validation Accuracy = 95.27%\n",
            "K = 14, Validation Accuracy = 95.27%\n",
            "K = 15, Validation Accuracy = 95.27%\n",
            "K = 16, Validation Accuracy = 95.27%\n",
            "K = 17, Validation Accuracy = 95.27%\n",
            "K = 18, Validation Accuracy = 95.95%\n",
            "K = 19, Validation Accuracy = 95.27%\n",
            "K = 20, Validation Accuracy = 95.95%\n",
            "K = 21, Validation Accuracy = 94.59%\n",
            "K = 22, Validation Accuracy = 95.27%\n",
            "K = 23, Validation Accuracy = 94.59%\n",
            "K = 24, Validation Accuracy = 93.92%\n",
            "K = 25, Validation Accuracy = 93.92%\n",
            "K = 26, Validation Accuracy = 93.92%\n",
            "K = 27, Validation Accuracy = 93.92%\n",
            "K = 28, Validation Accuracy = 93.92%\n",
            "K = 29, Validation Accuracy = 93.92%\n",
            "Best K: 8 with Validation Accuracy: 96.62%\n"
          ]
        }
      ],
      "source": [
        "best_k = None\n",
        "best_accuracy = 0\n",
        "euclidean = lambda x1, x2: np.sqrt(np.sum((x1 - x2)**2, axis=-1))\n",
        "\n",
        "# Convert y_validate from one-hot encoding to class indices if necessary\n",
        "y_validate_indices = np.argmax(y_validate, axis=1)\n",
        "\n",
        "# Try different values of K\n",
        "for K in range(1, 30):  # Assuming we are testing K from 1 to 19\n",
        "    model = KNN(K=K, distance_fn=euclidean)\n",
        "    model.fit(x_train, y_train)\n",
        "    y_pred = model.predict(x_validate)\n",
        "\n",
        "    # Calculate accuracy\n",
        "    accuracy = np.sum(y_pred == y_validate_indices) / len(y_validate_indices)\n",
        "    print(f'K = {K}, Validation Accuracy = {accuracy * 100:.2f}%')\n",
        "\n",
        "    # Update best K if current accuracy is better\n",
        "    if accuracy > best_accuracy:\n",
        "        best_accuracy = accuracy\n",
        "        best_k = K\n",
        "\n",
        "print(f'Best K: {best_k} with Validation Accuracy: {best_accuracy * 100:.2f}%')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r0YmPWkZBEmA"
      },
      "source": [
        "# Calculate the final evaluation metric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluate_acc(y_pred, y_test_indices):\n",
        "    return np.sum(y_pred == y_test_indices)/y_test_indices.shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mkknZmXagL_G",
        "outputId": "cf3a740a-5623-4d37-8835-134726894878"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "accuracy is 94.1.\n"
          ]
        }
      ],
      "source": [
        "# Choosing the best K according to the validation set above\n",
        "myK = 8\n",
        "euclidean = lambda x1, x2: np.sqrt(np.sum((x1 - x2)**2, axis=-1))\n",
        "\n",
        "model = KNN(K=myK, distance_fn=euclidean)\n",
        "\n",
        "y_pred = model.fit(x_train, y_train).predict(x_test)\n",
        "\n",
        "# This step is converting y_test from one-hot encoding back to class index\n",
        "y_test_indices = np.argmax(y_test, axis=1)\n",
        "\n",
        "accuracy = evaluate_acc(y_pred, y_test_indices)\n",
        "print(f'accuracy is {accuracy*100:.1f}.')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QxJ-hSe9CKBC"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "AQ4O7ME3e7bJ"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
